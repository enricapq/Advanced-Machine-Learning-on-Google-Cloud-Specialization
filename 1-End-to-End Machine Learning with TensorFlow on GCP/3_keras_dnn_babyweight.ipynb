{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Keras DNN model\n",
    "\n",
    "**Learning Objectives**\n",
    "\n",
    "1. Create input layers for raw features\n",
    "1. Create feature columns for inputs\n",
    "1. Create DNN dense hidden layers and output layer\n",
    "1. Build DNN model tying all of the pieces together\n",
    "1. Train and evaluate\n",
    "\n",
    "\n",
    "## Introduction \n",
    "In this notebook, we'll be using Keras to create a DNN model to predict the weight of a baby before it is born.\n",
    "\n",
    "We'll start by defining the CSV column names, label column, and column defaults for our data inputs. Then, we'll construct a tf.data Dataset of features and the label from the CSV files and create inputs layers for the raw features. Next, we'll set up feature columns for the model inputs and build a deep neural network in Keras. We'll create a custom evaluation metric and build our DNN model. Finally, we'll train and evaluate our model.\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in this student lab notebook -- try to complete this notebook first and then review the [solution notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/deepdive2/end_to_end_ml/solutions/keras_dnn_babyweight.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJ7ByvoXzpVI"
   },
   "source": [
    "## Set up environment variables and load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo chown -R jupyter:jupyter /home/jupyter/training-data-analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-bigquery==1.25.0\n",
      "  Downloading google_cloud_bigquery-1.25.0-py2.py3-none-any.whl (169 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.1/169.1 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-api-core<2.0dev,>=1.15.0\n",
      "  Downloading google_api_core-1.31.5-py2.py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-auth<2.0dev,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.35.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (3.19.4)\n",
      "Collecting google-cloud-core<2.0dev,>=1.1.0\n",
      "  Downloading google_cloud_core-1.7.2-py2.py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: six<2.0.0dev,>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-bigquery==1.25.0) (1.15.0)\n",
      "Collecting google-resumable-media<0.6dev,>=0.5.0\n",
      "  Downloading google_resumable_media-0.5.1-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2021.3)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (59.8.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.27.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (1.54.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (21.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (4.2.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (3.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.9.0->google-cloud-bigquery==1.25.0) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0dev,>=1.15.0->google-cloud-bigquery==1.25.0) (2.0.12)\n",
      "Installing collected packages: google-resumable-media, google-api-core, google-cloud-core, google-cloud-bigquery\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-cloud-storage 2.2.1 requires google-resumable-media>=2.3.2, but you have google-resumable-media 0.5.1 which is incompatible.\n",
      "cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 2.41.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-1.31.5 google-cloud-bigquery-1.25.0 google-cloud-core-1.7.2 google-resumable-media-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --user google-cloud-bigquery==1.25.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Restart your kernel to use updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kindly ignore the deprecation warnings and incompatibility errors related to google-cloud-storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.3\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set environment variables so that we can use them throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your current GCP Project Name is: qwiklabs-gcp-00-b88ed2a56757\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export PROJECT=$(gcloud config list project --format \"value(core.project)\")\n",
    "echo \"Your current GCP Project Name is: \"$PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"qwiklabs-gcp-00-b88ed2a56757\"  # Replace with your PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ML datasets by sampling using BigQuery\n",
    "\n",
    "We'll begin by sampling the BigQuery data to create smaller datasets. Let's create a BigQuery client that we'll use throughout the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bq = bigquery.Client(project = PROJECT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to figure out the right way to divide our hash values to get our desired splits. To do that we need to define some values to hash within the module. Feel free to play around with these values to get the perfect combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modulo_divisor = 100\n",
    "train_percent = 80.0\n",
    "eval_percent = 10.0\n",
    "\n",
    "train_buckets = int(modulo_divisor * train_percent / 100.0)\n",
    "eval_buckets = int(modulo_divisor * eval_percent / 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a series of queries to check if our bucketing values result in the correct sizes of each of our dataset splits and then adjust accordingly. Therefore, to make our code more compact and reusable, let's define a function to return the head of a dataframe produced from our queries up to a certain number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_dataframe_head_from_query(query, count=10):\n",
    "    \"\"\"Displays count rows from dataframe head from query.\n",
    "    \n",
    "    Args:\n",
    "        query: str, query to be run on BigQuery, results stored in dataframe.\n",
    "        count: int, number of results from head of dataframe to display.\n",
    "    Returns:\n",
    "        Dataframe head with count number of results.\n",
    "    \"\"\"\n",
    "    df = bq.query(\n",
    "        query + \" LIMIT {limit}\".format(\n",
    "            limit=count)).to_dataframe()\n",
    "\n",
    "    return df.head(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our first query, we're going to use the original query above to get our label, features, and columns to combine into our hash which we will use to perform our repeatable splitting. There are only a limited number of years, months, days, and states in the dataset. Let's see what the hash values are. We will need to include all of these extra columns to hash on to get a fairly uniform spread of the data. Feel free to try less or more in the hash and see how it changes your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>state</th>\n",
       "      <th>mother_birth_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.568469</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>2001</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>CA</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.807467</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>CA</td>\n",
       "      <td>Foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.313632</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.000575</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>IL</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.563162</td>\n",
       "      <td>False</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2001</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>KY</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.125340</td>\n",
       "      <td>False</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2001</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>MD</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.438397</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>MA</td>\n",
       "      <td>Foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.352416</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>MI</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.062305</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>2001</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>MN</td>\n",
       "      <td>MN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.251004</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>MS</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  plurality  gestation_weeks  year  \\\n",
       "0       7.568469     True          22          1               46  2001   \n",
       "1       8.807467     True          39          1               42  2001   \n",
       "2       8.313632     True          23          1               35  2001   \n",
       "3       8.000575    False          27          1               40  2001   \n",
       "4       6.563162    False          29          1               39  2001   \n",
       "5       7.125340    False          34          1               40  2001   \n",
       "6       7.438397    False          31          1               38  2001   \n",
       "7       7.352416     True          30          1               37  2001   \n",
       "8       8.062305     True          16          1               40  2001   \n",
       "9       7.251004     True          17          1               39  2001   \n",
       "\n",
       "   month  date state mother_birth_state  \n",
       "0      7     5    CA                 CA  \n",
       "1      8     3    CA            Foreign  \n",
       "2     10     7    IL                 IL  \n",
       "3      6     7    IL                 IL  \n",
       "4     11     7    KY                 IN  \n",
       "5     12     7    MD                 MD  \n",
       "6      4     3    MA            Foreign  \n",
       "7      5     7    MI                 MI  \n",
       "8     10     5    MN                 MN  \n",
       "9      2     5    MS                 MS  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get label, features, and columns to hash and split into buckets\n",
    "hash_cols_fixed_query = \"\"\"\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    year,\n",
    "    month,\n",
    "    CASE\n",
    "        WHEN day IS NULL THEN\n",
    "            CASE\n",
    "                WHEN wday IS NULL THEN 0\n",
    "                ELSE wday\n",
    "            END\n",
    "        ELSE day\n",
    "    END AS date,\n",
    "    IFNULL(state, \"Unknown\") AS state,\n",
    "    IFNULL(mother_birth_state, \"Unknown\") AS mother_birth_state\n",
    "FROM\n",
    "    publicdata.samples.natality\n",
    "WHERE\n",
    "    year > 2000\n",
    "    AND weight_pounds > 0\n",
    "    AND mother_age > 0\n",
    "    AND plurality > 0\n",
    "    AND gestation_weeks > 0\n",
    "\"\"\"\n",
    "\n",
    "display_dataframe_head_from_query(hash_cols_fixed_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `COALESCE` would provide the same result as the nested `CASE WHEN`. This is preferable when all we want is the first non-null instance. To be precise the `CASE WHEN` would become `COALESCE(wday, day, 0) AS date`. You can read more about it [here](https://cloud.google.com/bigquery/docs/reference/standard-sql/conditional_expressions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next query will combine our hash columns and will leave us just with our label, features, and our hash values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.063611</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>4762325092919148672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.687028</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>2341060194216507348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.561856</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>-8842767231851202242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.561856</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>7957807816914159435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.312733</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>-5961624242430066305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.627994</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>5493295634082918412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.251004</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>-2988893757655690534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.500126</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>-6735199252008114417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.125340</td>\n",
       "      <td>False</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>-3514093303120687641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.749249</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>2175328516857391398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  plurality  gestation_weeks  \\\n",
       "0       7.063611     True          32          1               37   \n",
       "1       4.687028     True          30          3               33   \n",
       "2       7.561856     True          20          1               39   \n",
       "3       7.561856     True          31          1               37   \n",
       "4       7.312733     True          32          1               40   \n",
       "5       7.627994    False          30          1               40   \n",
       "6       7.251004     True          33          1               37   \n",
       "7       7.500126    False          23          1               39   \n",
       "8       7.125340    False          33          1               39   \n",
       "9       7.749249     True          31          1               39   \n",
       "\n",
       "           hash_values  \n",
       "0  4762325092919148672  \n",
       "1  2341060194216507348  \n",
       "2 -8842767231851202242  \n",
       "3  7957807816914159435  \n",
       "4 -5961624242430066305  \n",
       "5  5493295634082918412  \n",
       "6 -2988893757655690534  \n",
       "7 -6735199252008114417  \n",
       "8 -3514093303120687641  \n",
       "9  2175328516857391398  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_query = \"\"\"\n",
    "SELECT\n",
    "    weight_pounds,\n",
    "    is_male,\n",
    "    mother_age,\n",
    "    plurality,\n",
    "    gestation_weeks,\n",
    "    FARM_FINGERPRINT(\n",
    "        CONCAT(\n",
    "            CAST(year AS STRING),\n",
    "            CAST(month AS STRING),\n",
    "            CAST(date AS STRING),\n",
    "            CAST(state AS STRING),\n",
    "            CAST(mother_birth_state AS STRING)\n",
    "        )\n",
    "    ) AS hash_values\n",
    "FROM\n",
    "    ({CTE_hash_cols_fixed})\n",
    "\"\"\".format(CTE_hash_cols_fixed=hash_cols_fixed_query)\n",
    "\n",
    "display_dataframe_head_from_query(data_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next query is going to find the counts of each of the unique 657484 `hash_values`. This will be our first step at making actual hash buckets for our split via the `GROUP BY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash_values</th>\n",
       "      <th>num_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6132026233917866995</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4914360558995864413</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9192824352349387771</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3498437247564591016</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1325027398661814723</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2170550628057791976</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2959046272092023672</td>\n",
       "      <td>1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6359047490015401237</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8513493640060418688</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1569657028734518022</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hash_values  num_records\n",
       "0 -6132026233917866995          228\n",
       "1  4914360558995864413           57\n",
       "2 -9192824352349387771         1646\n",
       "3 -3498437247564591016           12\n",
       "4  1325027398661814723            8\n",
       "5  2170550628057791976         1305\n",
       "6 -2959046272092023672         1167\n",
       "7  6359047490015401237          753\n",
       "8  8513493640060418688          555\n",
       "9 -1569657028734518022           27"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the counts of each of the unique hash of our splitting column\n",
    "first_bucketing_query = \"\"\"\n",
    "SELECT\n",
    "    hash_values,\n",
    "    COUNT(*) AS num_records\n",
    "FROM\n",
    "    ({CTE_data})\n",
    "GROUP BY\n",
    "    hash_values\n",
    "\"\"\".format(CTE_data=data_query)\n",
    "\n",
    "display_dataframe_head_from_query(first_bucketing_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query below performs a second layer of bucketing where now for each of these bucket indices we count the number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>num_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>281627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>263367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>355099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>402627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>372457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96</td>\n",
       "      <td>529357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>236637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>384793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>548778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>76</td>\n",
       "      <td>354090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  num_records\n",
       "0            46       281627\n",
       "1            15       263367\n",
       "2            60       355099\n",
       "3            66       402627\n",
       "4            67       372457\n",
       "5            96       529357\n",
       "6             9       236637\n",
       "7            19       384793\n",
       "8             6       548778\n",
       "9            76       354090"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of records in each of the hash buckets\n",
    "second_bucketing_query = \"\"\"\n",
    "SELECT\n",
    "    ABS(MOD(hash_values, {modulo_divisor})) AS bucket_index,\n",
    "    SUM(num_records) AS num_records\n",
    "FROM\n",
    "    ({CTE_first_bucketing})\n",
    "GROUP BY\n",
    "    ABS(MOD(hash_values, {modulo_divisor}))\n",
    "\"\"\".format(\n",
    "    CTE_first_bucketing=first_bucketing_query, modulo_divisor=modulo_divisor)\n",
    "\n",
    "display_dataframe_head_from_query(second_bucketing_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of records is hard for us to easily understand the split, so we will normalize the count into percentage of the data in each of the hash buckets in the next query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>559019</td>\n",
       "      <td>0.016934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>250505</td>\n",
       "      <td>0.007588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>247072</td>\n",
       "      <td>0.007484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>480999</td>\n",
       "      <td>0.014571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>256517</td>\n",
       "      <td>0.007771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53</td>\n",
       "      <td>230298</td>\n",
       "      <td>0.006976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>246041</td>\n",
       "      <td>0.007453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73</td>\n",
       "      <td>411771</td>\n",
       "      <td>0.012474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>71</td>\n",
       "      <td>260774</td>\n",
       "      <td>0.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>87</td>\n",
       "      <td>523881</td>\n",
       "      <td>0.015870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  num_records  percent_records\n",
       "0            23       559019         0.016934\n",
       "1            35       250505         0.007588\n",
       "2            21       247072         0.007484\n",
       "3            74       480999         0.014571\n",
       "4            54       256517         0.007771\n",
       "5            53       230298         0.006976\n",
       "6            36       246041         0.007453\n",
       "7            73       411771         0.012474\n",
       "8            71       260774         0.007900\n",
       "9            87       523881         0.015870"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the overall percentages\n",
    "percentages_query = \"\"\"\n",
    "SELECT\n",
    "    bucket_index,\n",
    "    num_records,\n",
    "    CAST(num_records AS FLOAT64) / (\n",
    "    SELECT\n",
    "        SUM(num_records)\n",
    "    FROM\n",
    "        ({CTE_second_bucketing})) AS percent_records\n",
    "FROM\n",
    "    ({CTE_second_bucketing})\n",
    "\"\"\".format(CTE_second_bucketing=second_bucketing_query)\n",
    "\n",
    "display_dataframe_head_from_query(percentages_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now select the range of buckets to be used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>229541</td>\n",
       "      <td>0.006953</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>244850</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>285539</td>\n",
       "      <td>0.008650</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>410226</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>204972</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>423507</td>\n",
       "      <td>0.012829</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79</td>\n",
       "      <td>403701</td>\n",
       "      <td>0.012229</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>75</td>\n",
       "      <td>367455</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>65</td>\n",
       "      <td>289303</td>\n",
       "      <td>0.008764</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>277395</td>\n",
       "      <td>0.008403</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  num_records  percent_records dataset_name\n",
       "0            72       229541         0.006953        train\n",
       "1            41       244850         0.007417        train\n",
       "2            70       285539         0.008650        train\n",
       "3            33       410226         0.012427        train\n",
       "4            52       204972         0.006209        train\n",
       "5            32       423507         0.012829        train\n",
       "6            79       403701         0.012229        train\n",
       "7            75       367455         0.011131        train\n",
       "8            65       289303         0.008764        train\n",
       "9             0       277395         0.008403        train"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose hash buckets for training and pull in their statistics\n",
    "train_query = \"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    \"train\" AS dataset_name\n",
    "FROM\n",
    "    ({CTE_percentages})\n",
    "WHERE\n",
    "    bucket_index >= 0\n",
    "    AND bucket_index < {train_buckets}\n",
    "\"\"\".format(\n",
    "    CTE_percentages=percentages_query,\n",
    "    train_buckets=train_buckets)\n",
    "\n",
    "display_dataframe_head_from_query(train_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same by selecting the range of buckets to be used evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85</td>\n",
       "      <td>368045</td>\n",
       "      <td>0.011149</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87</td>\n",
       "      <td>523881</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88</td>\n",
       "      <td>423809</td>\n",
       "      <td>0.012838</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84</td>\n",
       "      <td>341155</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>274489</td>\n",
       "      <td>0.008315</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81</td>\n",
       "      <td>233538</td>\n",
       "      <td>0.007074</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>82</td>\n",
       "      <td>468179</td>\n",
       "      <td>0.014182</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>83</td>\n",
       "      <td>411258</td>\n",
       "      <td>0.012458</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89</td>\n",
       "      <td>256482</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80</td>\n",
       "      <td>312489</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  num_records  percent_records dataset_name\n",
       "0            85       368045         0.011149         eval\n",
       "1            87       523881         0.015870         eval\n",
       "2            88       423809         0.012838         eval\n",
       "3            84       341155         0.010334         eval\n",
       "4            86       274489         0.008315         eval\n",
       "5            81       233538         0.007074         eval\n",
       "6            82       468179         0.014182         eval\n",
       "7            83       411258         0.012458         eval\n",
       "8            89       256482         0.007770         eval\n",
       "9            80       312489         0.009466         eval"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose hash buckets for validation and pull in their statistics\n",
    "eval_query = \"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    \"eval\" AS dataset_name\n",
    "FROM\n",
    "    ({CTE_percentages})\n",
    "WHERE\n",
    "    bucket_index >= {train_buckets}\n",
    "    AND bucket_index < {cum_eval_buckets}\n",
    "\"\"\".format(\n",
    "    CTE_percentages=percentages_query,\n",
    "    train_buckets=train_buckets,\n",
    "    cum_eval_buckets=train_buckets + eval_buckets)\n",
    "\n",
    "display_dataframe_head_from_query(eval_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll select the hash buckets to be used for the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>374697</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>333267</td>\n",
       "      <td>0.010096</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97</td>\n",
       "      <td>480790</td>\n",
       "      <td>0.014564</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92</td>\n",
       "      <td>336735</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>313544</td>\n",
       "      <td>0.009498</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96</td>\n",
       "      <td>529357</td>\n",
       "      <td>0.016036</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>99</td>\n",
       "      <td>223334</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>94</td>\n",
       "      <td>431001</td>\n",
       "      <td>0.013056</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>93</td>\n",
       "      <td>215710</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90</td>\n",
       "      <td>286465</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bucket_index  num_records  percent_records dataset_name\n",
       "0            98       374697         0.011351         test\n",
       "1            91       333267         0.010096         test\n",
       "2            97       480790         0.014564         test\n",
       "3            92       336735         0.010201         test\n",
       "4            95       313544         0.009498         test\n",
       "5            96       529357         0.016036         test\n",
       "6            99       223334         0.006765         test\n",
       "7            94       431001         0.013056         test\n",
       "8            93       215710         0.006534         test\n",
       "9            90       286465         0.008678         test"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose hash buckets for testing and pull in their statistics\n",
    "test_query = \"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    \"test\" AS dataset_name\n",
    "FROM\n",
    "    ({CTE_percentages})\n",
    "WHERE\n",
    "    bucket_index >= {cum_eval_buckets}\n",
    "    AND bucket_index < {modulo_divisor}\n",
    "\"\"\".format(\n",
    "    CTE_percentages=percentages_query,\n",
    "    cum_eval_buckets=train_buckets + eval_buckets,\n",
    "    modulo_divisor=modulo_divisor)\n",
    "\n",
    "display_dataframe_head_from_query(test_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below query, we'll `UNION ALL` all of the datasets together so that all three sets of hash buckets will be within one table. We added `dataset_id` so that we can sort on it in the query after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>bucket_index</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "      <th>dataset_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>223334</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "      <td>336735</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>529357</td>\n",
       "      <td>0.016036</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>95</td>\n",
       "      <td>313544</td>\n",
       "      <td>0.009498</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>84</td>\n",
       "      <td>341155</td>\n",
       "      <td>0.010334</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>423809</td>\n",
       "      <td>0.012838</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>286465</td>\n",
       "      <td>0.008678</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>215710</td>\n",
       "      <td>0.006534</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>449280</td>\n",
       "      <td>0.013610</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>412875</td>\n",
       "      <td>0.012507</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id  bucket_index  num_records  percent_records dataset_name\n",
       "0           2            99       223334         0.006765         test\n",
       "1           2            92       336735         0.010201         test\n",
       "2           2            96       529357         0.016036         test\n",
       "3           2            95       313544         0.009498         test\n",
       "4           1            84       341155         0.010334         eval\n",
       "5           1            88       423809         0.012838         eval\n",
       "6           2            90       286465         0.008678         test\n",
       "7           2            93       215710         0.006534         test\n",
       "8           0             5       449280         0.013610        train\n",
       "9           0            12       412875         0.012507        train"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Union the training, validation, and testing dataset statistics\n",
    "union_query = \"\"\"\n",
    "SELECT\n",
    "    0 AS dataset_id,\n",
    "    *\n",
    "FROM\n",
    "    ({CTE_train})\n",
    "UNION ALL\n",
    "SELECT\n",
    "    1 AS dataset_id,\n",
    "    *\n",
    "FROM\n",
    "    ({CTE_eval})\n",
    "UNION ALL\n",
    "SELECT\n",
    "    2 AS dataset_id,\n",
    "    *\n",
    "FROM\n",
    "    ({CTE_test})\n",
    "\"\"\".format(CTE_train=train_query, CTE_eval=eval_query, CTE_test=test_query)\n",
    "\n",
    "display_dataframe_head_from_query(union_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll show the final split between train, eval, and test sets. We can see both the number of records and percent of the total data. It is really close to that we were hoping to get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>num_records</th>\n",
       "      <th>percent_records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>25873134</td>\n",
       "      <td>0.783765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>eval</td>\n",
       "      <td>3613325</td>\n",
       "      <td>0.109457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>3524900</td>\n",
       "      <td>0.106778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_id dataset_name  num_records  percent_records\n",
       "0           0        train     25873134         0.783765\n",
       "1           1         eval      3613325         0.109457\n",
       "2           2         test      3524900         0.106778"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show final splitting and associated statistics\n",
    "split_query = \"\"\"\n",
    "SELECT\n",
    "    dataset_id,\n",
    "    dataset_name,\n",
    "    SUM(num_records) AS num_records,\n",
    "    SUM(percent_records) AS percent_records\n",
    "FROM\n",
    "    ({CTE_union})\n",
    "GROUP BY\n",
    "    dataset_id,\n",
    "    dataset_name\n",
    "ORDER BY\n",
    "    dataset_id\n",
    "\"\"\".format(CTE_union=union_query)\n",
    "\n",
    "display_dataframe_head_from_query(split_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know that our splitting values produce a good global splitting on our data, here's a way to get a well-distributed portion of the data in such a way that the train, eval, test sets do not overlap and takes a subsample of our global splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7733 examples in the train dataset.\n",
      "There are 1037 examples in the validation dataset.\n",
      "There are 561 examples in the test dataset.\n"
     ]
    }
   ],
   "source": [
    "# every_n allows us to subsample from each of the hash values\n",
    "# This helps us get approximately the record counts we want\n",
    "every_n = 1000\n",
    "\n",
    "splitting_string = \"ABS(MOD(hash_values, {0} * {1}))\".format(every_n, modulo_divisor)\n",
    "\n",
    "def create_data_split_sample_df(query_string, splitting_string, lo, up):\n",
    "    \"\"\"Creates a dataframe with a sample of a data split.\n",
    "\n",
    "    Args:\n",
    "        query_string: str, query to run to generate splits.\n",
    "        splitting_string: str, modulo string to split by.\n",
    "        lo: float, lower bound for bucket filtering for split.\n",
    "        up: float, upper bound for bucket filtering for split.\n",
    "    Returns:\n",
    "        Dataframe containing data split sample.\n",
    "    \"\"\"\n",
    "    query = \"SELECT * FROM ({0}) WHERE {1} >= {2} and {1} < {3}\".format(\n",
    "        query_string, splitting_string, int(lo), int(up))\n",
    "\n",
    "    df = bq.query(query).to_dataframe()\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = create_data_split_sample_df(\n",
    "    data_query, splitting_string,\n",
    "    lo=0, up=train_percent)\n",
    "\n",
    "eval_df = create_data_split_sample_df(\n",
    "    data_query, splitting_string,\n",
    "    lo=train_percent, up=train_percent + eval_percent)\n",
    "\n",
    "test_df = create_data_split_sample_df(\n",
    "    data_query, splitting_string,\n",
    "    lo=train_percent + eval_percent, up=modulo_divisor)\n",
    "\n",
    "print(\"There are {} examples in the train dataset.\".format(len(train_df)))\n",
    "print(\"There are {} examples in the validation dataset.\".format(len(eval_df)))\n",
    "print(\"There are {} examples in the test dataset.\".format(len(test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data using Pandas\n",
    "\n",
    "We'll perform a few preprocessing steps to the data in our dataset. Let's add extra rows to simulate the lack of ultrasound. That is we'll duplicate some rows and make the `is_male` field be `Unknown`. Also, if there is more than child we'll change the `plurality` to `Multiple(2+)`. While we're at it, we'll also change the plurality column to be a string. We'll perform these operations below. \n",
    "\n",
    "Let's start by examining the training dataset as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.500126</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>5052252520303500071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.217443</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>-5549088115530700048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.936641</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2054179216119800044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.938355</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2749458901984200063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.312733</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>-6784884401981100070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds  is_male  mother_age  plurality  gestation_weeks  \\\n",
       "0       7.500126    False          40          1               43   \n",
       "1       4.217443    False          40          2               37   \n",
       "2       7.936641     True          37          1               37   \n",
       "3       4.938355    False          24          1               38   \n",
       "4       7.312733     True          24          1               39   \n",
       "\n",
       "           hash_values  \n",
       "0  5052252520303500071  \n",
       "1 -5549088115530700048  \n",
       "2  2054179216119800044  \n",
       "3  2749458901984200063  \n",
       "4 -6784884401981100070  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, notice that there are some very important numeric fields that are missing in some rows (the count in Pandas doesn't count missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7733.000000</td>\n",
       "      <td>7733.000000</td>\n",
       "      <td>7733.000000</td>\n",
       "      <td>7733.000000</td>\n",
       "      <td>7.733000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.264415</td>\n",
       "      <td>28.213371</td>\n",
       "      <td>1.035691</td>\n",
       "      <td>38.691064</td>\n",
       "      <td>-2.984870e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.303220</td>\n",
       "      <td>6.134232</td>\n",
       "      <td>0.201568</td>\n",
       "      <td>2.531921</td>\n",
       "      <td>5.590715e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.562179</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-9.210618e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.624891</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>-6.781866e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.345803</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>5.057323e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.062305</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.896699e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.563246</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>9.203641e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight_pounds   mother_age    plurality  gestation_weeks   hash_values\n",
       "count    7733.000000  7733.000000  7733.000000      7733.000000  7.733000e+03\n",
       "mean        7.264415    28.213371     1.035691        38.691064 -2.984870e+17\n",
       "std         1.303220     6.134232     0.201568         2.531921  5.590715e+18\n",
       "min         0.562179    13.000000     1.000000        18.000000 -9.210618e+18\n",
       "25%         6.624891    23.000000     1.000000        38.000000 -6.781866e+18\n",
       "50%         7.345803    28.000000     1.000000        39.000000  5.057323e+17\n",
       "75%         8.062305    33.000000     1.000000        40.000000  4.896699e+18\n",
       "max        11.563246    48.000000     4.000000        47.000000  9.203641e+18"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always crucial to clean raw data before using in machine learning, so we have a preprocessing step. We'll define a `preprocess` function below. Note that the mother's age is an input to our model so users will have to provide the mother's age; otherwise, our service won't work. The features we use for our model were chosen because they are such good predictors and because they are easy enough to collect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    \"\"\" Preprocess pandas dataframe for augmented babyweight data.\n",
    "    \n",
    "    Args:\n",
    "        df: Dataframe containing raw babyweight data.\n",
    "    Returns:\n",
    "        Pandas dataframe containing preprocessed raw babyweight data as well\n",
    "            as simulated no ultrasound data masking some of the original data.\n",
    "    \"\"\"\n",
    "    # Clean up raw data\n",
    "    # Filter out what we don\"t want to use for training\n",
    "    df = df[df.weight_pounds > 0]\n",
    "    df = df[df.mother_age > 0]\n",
    "    df = df[df.gestation_weeks > 0]\n",
    "    df = df[df.plurality > 0]\n",
    "\n",
    "    # Modify plurality field to be a string\n",
    "    twins_etc = dict(zip([1,2,3,4,5],\n",
    "                   [\"Single(1)\",\n",
    "                    \"Twins(2)\",\n",
    "                    \"Triplets(3)\",\n",
    "                    \"Quadruplets(4)\",\n",
    "                    \"Quintuplets(5)\"]))\n",
    "    df[\"plurality\"].replace(twins_etc, inplace=True)\n",
    "\n",
    "    # Clone data and mask certain columns to simulate lack of ultrasound\n",
    "    no_ultrasound = df.copy(deep=True)\n",
    "\n",
    "    # Modify is_male\n",
    "    no_ultrasound[\"is_male\"] = \"Unknown\"\n",
    "    \n",
    "    # Modify plurality\n",
    "    condition = no_ultrasound[\"plurality\"] != \"Single(1)\"\n",
    "    no_ultrasound.loc[condition, \"plurality\"] = \"Multiple(2+)\"\n",
    "\n",
    "    # Concatenate both datasets together and shuffle\n",
    "    return pd.concat(\n",
    "        [df, no_ultrasound]).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process the train, eval, test set and see a small sample of the training data after our preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess(train_df)\n",
    "eval_df = preprocess(eval_df)\n",
    "test_df = preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.832125</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>35</td>\n",
       "      <td>-8717259940738900003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.874013</td>\n",
       "      <td>False</td>\n",
       "      <td>34</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>38</td>\n",
       "      <td>8936877654883400016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.125748</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>38</td>\n",
       "      <td>-1967678091068000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.874912</td>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>40</td>\n",
       "      <td>-6848352519903300073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.948970</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>39</td>\n",
       "      <td>-5791317757424000074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weight_pounds is_male  mother_age  plurality  gestation_weeks  \\\n",
       "0       6.832125    True          30  Single(1)               35   \n",
       "1       6.874013   False          34  Single(1)               38   \n",
       "2       5.125748   False          18  Single(1)               38   \n",
       "3       7.874912   False          36  Single(1)               40   \n",
       "4       6.948970    True          18  Single(1)               39   \n",
       "\n",
       "           hash_values  \n",
       "0 -8717259940738900003  \n",
       "1  8936877654883400016  \n",
       "2 -1967678091068000059  \n",
       "3 -6848352519903300073  \n",
       "4 -5791317757424000074  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>is_male</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>plurality</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15461</th>\n",
       "      <td>7.312733</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>38</td>\n",
       "      <td>7530857978474000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15462</th>\n",
       "      <td>8.560550</td>\n",
       "      <td>False</td>\n",
       "      <td>26</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>40</td>\n",
       "      <td>2749458901984200063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15463</th>\n",
       "      <td>6.188376</td>\n",
       "      <td>False</td>\n",
       "      <td>25</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>38</td>\n",
       "      <td>505732274561700014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15464</th>\n",
       "      <td>8.201196</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>22</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>40</td>\n",
       "      <td>-73800273226100053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>7.813183</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>20</td>\n",
       "      <td>Single(1)</td>\n",
       "      <td>40</td>\n",
       "      <td>505732274561700014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight_pounds  is_male  mother_age  plurality  gestation_weeks  \\\n",
       "15461       7.312733     True          30  Single(1)               38   \n",
       "15462       8.560550    False          26  Single(1)               40   \n",
       "15463       6.188376    False          25  Single(1)               38   \n",
       "15464       8.201196  Unknown          22  Single(1)               40   \n",
       "15465       7.813183  Unknown          20  Single(1)               40   \n",
       "\n",
       "               hash_values  \n",
       "15461  7530857978474000075  \n",
       "15462  2749458901984200063  \n",
       "15463   505732274561700014  \n",
       "15464   -73800273226100053  \n",
       "15465   505732274561700014  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look again at a summary of the dataset. Note that we only see numeric columns, so `plurality` does not show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight_pounds</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>hash_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15466.000000</td>\n",
       "      <td>15466.000000</td>\n",
       "      <td>15466.000000</td>\n",
       "      <td>1.546600e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.264415</td>\n",
       "      <td>28.213371</td>\n",
       "      <td>38.691064</td>\n",
       "      <td>-2.984870e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.303178</td>\n",
       "      <td>6.134034</td>\n",
       "      <td>2.531839</td>\n",
       "      <td>5.590534e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.562179</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-9.210618e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.624891</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>-6.781866e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.345803</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>5.057323e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.062305</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>4.896699e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.563246</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>9.203641e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       weight_pounds    mother_age  gestation_weeks   hash_values\n",
       "count   15466.000000  15466.000000     15466.000000  1.546600e+04\n",
       "mean        7.264415     28.213371        38.691064 -2.984870e+17\n",
       "std         1.303178      6.134034         2.531839  5.590534e+18\n",
       "min         0.562179     13.000000        18.000000 -9.210618e+18\n",
       "25%         6.624891     23.000000        38.000000 -6.781866e+18\n",
       "50%         7.345803     28.000000        39.000000  5.057323e+17\n",
       "75%         8.062305     33.000000        40.000000  4.896699e+18\n",
       "max        11.563246     48.000000        47.000000  9.203641e+18"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to .csv files \n",
    "\n",
    "In the final versions, we want to read from files, not Pandas dataframes. So, we write the Pandas dataframes out as csv files. Using csv files gives us the advantage of shuffling during read. This is important for distributed training because some workers might be slower than others, and shuffling the data helps prevent the same data from being assigned to the slow workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "columns = [\"weight_pounds\",\n",
    "           \"is_male\",\n",
    "           \"mother_age\",\n",
    "           \"plurality\",\n",
    "           \"gestation_weeks\"]\n",
    "\n",
    "# Write out CSV files\n",
    "train_df.to_csv(\n",
    "    path_or_buf=\"train.csv\", columns=columns, header=False, index=False)\n",
    "eval_df.to_csv(\n",
    "    path_or_buf=\"eval.csv\", columns=columns, header=False, index=False)\n",
    "test_df.to_csv(\n",
    "    path_or_buf=\"test.csv\", columns=columns, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2074 eval.csv\n",
      "  1122 test.csv\n",
      " 15466 train.csv\n",
      " 18662 total\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wc -l *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> eval.csv <==\n",
      "7.62578964258,False,34,Single(1),40\n",
      "5.8753192823,Unknown,38,Single(1),39\n",
      "8.50102482272,False,30,Single(1),41\n",
      "6.4044287111,Unknown,33,Multiple(2+),38\n",
      "8.24969784404,True,20,Single(1),41\n",
      "9.12493302418,False,31,Single(1),39\n",
      "7.12534030784,True,17,Single(1),40\n",
      "9.93843877096,Unknown,24,Single(1),40\n",
      "6.4374980503999994,True,22,Single(1),40\n",
      "8.62448368944,Unknown,19,Single(1),40\n",
      "\n",
      "==> test.csv <==\n",
      "6.75055446244,Unknown,19,Single(1),40\n",
      "5.56226287026,Unknown,29,Single(1),37\n",
      "7.1870697412,True,17,Single(1),37\n",
      "6.9996768185,Unknown,21,Single(1),39\n",
      "6.37576861704,Unknown,23,Single(1),38\n",
      "6.6800065386,Unknown,31,Multiple(2+),36\n",
      "7.50012615324,Unknown,27,Single(1),36\n",
      "7.2862777591,False,23,Single(1),41\n",
      "7.25100379718,False,31,Single(1),39\n",
      "7.1870697412,Unknown,24,Single(1),38\n",
      "\n",
      "==> train.csv <==\n",
      "6.83212549938,True,30,Single(1),35\n",
      "6.87401332916,False,34,Single(1),38\n",
      "5.1257475915,False,18,Single(1),38\n",
      "7.87491199864,False,36,Single(1),40\n",
      "6.94897049824,True,18,Single(1),39\n",
      "6.9996768185,True,31,Single(1),39\n",
      "5.24920645822,Unknown,35,Single(1),38\n",
      "6.4374980503999994,Unknown,21,Single(1),40\n",
      "6.1883756943399995,False,20,Single(1),39\n",
      "7.25100379718,Unknown,23,Single(1),40\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> eval.csv <==\n",
      "7.06361087448,False,35,Single(1),37\n",
      "7.5618555866,False,27,Single(1),40\n",
      "6.3118345610599995,Unknown,34,Single(1),37\n",
      "9.12493302418,Unknown,34,Single(1),40\n",
      "8.5870051049,True,41,Single(1),38\n",
      "6.87621795178,True,31,Twins(2),44\n",
      "7.25100379718,Unknown,32,Single(1),40\n",
      "10.62407640578,True,35,Single(1),40\n",
      "6.0009827716399995,True,34,Single(1),38\n",
      "5.8135898489399995,Unknown,29,Single(1),38\n",
      "\n",
      "==> test.csv <==\n",
      "7.29509624958,Unknown,28,Single(1),39\n",
      "7.34580256984,True,23,Single(1),40\n",
      "6.4992274837599995,True,35,Single(1),38\n",
      "8.62448368944,False,18,Single(1),42\n",
      "6.4374980503999994,Unknown,27,Single(1),37\n",
      "8.062304921339999,Unknown,21,Single(1),37\n",
      "7.7492485093,Unknown,38,Single(1),40\n",
      "1.6248068709399999,False,41,Single(1),22\n",
      "7.7492485093,True,21,Single(1),41\n",
      "9.18666245754,True,34,Single(1),43\n",
      "\n",
      "==> train.csv <==\n",
      "6.75055446244,False,30,Single(1),41\n",
      "6.93794738514,Unknown,35,Single(1),38\n",
      "6.1244416383599996,Unknown,35,Single(1),38\n",
      "6.686620406459999,True,25,Single(1),39\n",
      "7.3744626639,Unknown,33,Single(1),40\n",
      "7.31273323054,True,30,Single(1),38\n",
      "8.560549633459999,False,26,Single(1),40\n",
      "6.1883756943399995,False,25,Single(1),38\n",
      "8.2011961464,Unknown,22,Single(1),40\n",
      "7.81318256528,Unknown,20,Single(1),40\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tail *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval.csv\n",
      "test.csv\n",
      "train.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls *.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> eval.csv <==\n",
      "7.62578964258,False,34,Single(1),40\n",
      "5.8753192823,Unknown,38,Single(1),39\n",
      "8.50102482272,False,30,Single(1),41\n",
      "6.4044287111,Unknown,33,Multiple(2+),38\n",
      "8.24969784404,True,20,Single(1),41\n",
      "\n",
      "==> test.csv <==\n",
      "6.75055446244,Unknown,19,Single(1),40\n",
      "5.56226287026,Unknown,29,Single(1),37\n",
      "7.1870697412,True,17,Single(1),37\n",
      "6.9996768185,Unknown,21,Single(1),39\n",
      "6.37576861704,Unknown,23,Single(1),38\n",
      "\n",
      "==> train.csv <==\n",
      "6.83212549938,True,30,Single(1),35\n",
      "6.87401332916,False,34,Single(1),38\n",
      "5.1257475915,False,18,Single(1),38\n",
      "7.87491199864,False,36,Single(1),40\n",
      "6.94897049824,True,18,Single(1),39\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -5 *.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set CSV Columns, label column, and column defaults.\n",
    "\n",
    "Now that we have verified that our CSV files exist, we need to set a few things that we will be using in our input function.\n",
    "* `CSV_COLUMNS` is going to be our header name of our column. Make sure that they are in the same order as in the CSV files\n",
    "* `LABEL_COLUMN` is the header name of the column that is our label. We will need to know this to pop it from our features dictionary.\n",
    "* `DEFAULTS` is a list with the same length as `CSV_COLUMNS`, i.e. there is a default for each column in our CSVs. Each element is a list itself with the default value for that CSV column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine CSV, label, and key columns\n",
    "# Create list of string column headers, make sure order matches.\n",
    "CSV_COLUMNS = [\"weight_pounds\",\n",
    "               \"is_male\",\n",
    "               \"mother_age\",\n",
    "               \"plurality\",\n",
    "               \"gestation_weeks\"]\n",
    "\n",
    "# Add string name for label column\n",
    "LABEL_COLUMN = \"weight_pounds\"\n",
    "\n",
    "# Set default values for each CSV column as a list of lists.\n",
    "# Treat is_male and plurality as strings.\n",
    "DEFAULTS = [[0.0], [\"null\"], [0.0], [\"null\"], [0.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset of features and label from CSV files.\n",
    "\n",
    "Next, we will write an input_fn to read the data. Since we are reading from CSV files we can save ourselves from trying to recreate the wheel and can use `tf.data.experimental.make_csv_dataset`. This will create a CSV dataset object. However we will need to divide the columns up into features and a label. We can do this by applying the map method to our dataset and popping our label column off of our dictionary of feature tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_and_labels(row_data):\n",
    "    \"\"\"Splits features and labels from feature dictionary.\n",
    "\n",
    "    Args:\n",
    "        row_data: Dictionary of CSV column names and tensor values.\n",
    "    Returns:\n",
    "        Dictionary of feature tensors and label tensor.\n",
    "    \"\"\"\n",
    "    label = row_data.pop(LABEL_COLUMN)\n",
    "\n",
    "    return row_data, label  # features, label\n",
    "\n",
    "\n",
    "def load_dataset(pattern, batch_size=1, mode='eval'):\n",
    "    \"\"\"Loads dataset using the tf.data API from CSV files.\n",
    "\n",
    "    Args:\n",
    "        pattern: str, file pattern to glob into list of files.\n",
    "        batch_size: int, the number of examples per batch.\n",
    "        mode: 'train' | 'eval' to determine if training or evaluating.\n",
    "    Returns:\n",
    "        `Dataset` object.\n",
    "    \"\"\"\n",
    "    # Make a CSV dataset\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_pattern=pattern,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_COLUMNS,\n",
    "        column_defaults=DEFAULTS,\n",
    "        ignore_errors=True)\n",
    "\n",
    "    # Map dataset to features and label\n",
    "    dataset = dataset.map(map_func=features_and_labels)  # features, label\n",
    "\n",
    "    # Shuffle and repeat for training\n",
    "    if mode == 'train':\n",
    "        dataset = dataset.shuffle(buffer_size=1000).repeat()\n",
    "\n",
    "    # Take advantage of multi-threading; 1=AUTOTUNE\n",
    "    dataset = dataset.prefetch(buffer_size=1)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input layers for raw features.\n",
    "\n",
    "We'll need to get the data to read in by our input function to our model function, but just how do we go about connecting the dots? We can use Keras input layers [(tf.Keras.layers.Input)](https://www.tensorflow.org/api_docs/python/tf/keras/Input) by defining:\n",
    "* shape: A shape tuple (integers), not including the batch size. For instance, shape=(32,) indicates that the expected input will be batches of 32-dimensional vectors. Elements of this tuple can be None; 'None' elements represent dimensions where the shape is not known.\n",
    "* name: An optional name string for the layer. Should be unique in a model (do not reuse the same name twice). It will be autogenerated if it isn't provided.\n",
    "* dtype: The data type expected by the input, as a string (float32, float64, int32...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJ7ByvoXzpVI"
   },
   "source": [
    "**Lab Task #1:** Creating input layers for raw features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_layers():\n",
    "    \"\"\"Creates dictionary of input layers for each feature.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of `tf.Keras.layers.Input` layers for each feature.\n",
    "    \"\"\"\n",
    "    inputs = {\n",
    "        colname: tf.keras.layers.Input(\n",
    "            name=colname, shape=(), dtype=\"float32\")\n",
    "        for colname in [\"mother_age\", \"gestation_weeks\"]}\n",
    "\n",
    "    inputs.update({\n",
    "        colname: tf.keras.layers.Input(\n",
    "            name=colname, shape=(), dtype=\"string\")\n",
    "        for colname in [\"is_male\", \"plurality\"]})\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature columns for inputs.\n",
    "\n",
    "Next, define the feature columns. `mother_age` and `gestation_weeks` should be numeric. The others, `is_male` and `plurality`, should be categorical. Remember, only dense feature columns can be inputs to a DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJ7ByvoXzpVI"
   },
   "source": [
    "**Lab Task #2:** Creating feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_fc(name, values):\n",
    "    \"\"\"Helper function to wrap categorical feature by indicator column.\n",
    "\n",
    "    Args:\n",
    "        name: str, name of feature.\n",
    "        values: list, list of strings of categorical values.\n",
    "    Returns:\n",
    "        Indicator column of categorical feature.\n",
    "    \"\"\"\n",
    "    cat_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "            key=name, vocabulary_list=values)\n",
    "\n",
    "    return tf.feature_column.indicator_column(categorical_column=cat_column)\n",
    "\n",
    "\n",
    "def create_feature_columns():\n",
    "    \"\"\"Creates dictionary of feature columns from inputs.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of feature columns.\n",
    "    \"\"\"\n",
    "    feature_columns = {\n",
    "        colname : tf.feature_column.numeric_column(key=colname)\n",
    "           for colname in [\"mother_age\", \"gestation_weeks\"]\n",
    "    }\n",
    "\n",
    "    feature_columns[\"is_male\"] = categorical_fc(\n",
    "        \"is_male\", [\"True\", \"False\", \"Unknown\"])\n",
    "    feature_columns[\"plurality\"] = categorical_fc(\n",
    "        \"plurality\", [\"Single(1)\", \"Twins(2)\", \"Triplets(3)\",\n",
    "                      \"Quadruplets(4)\", \"Quintuplets(5)\", \"Multiple(2+)\"])\n",
    "\n",
    "    return feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DNN dense hidden layers and output layer.\n",
    "\n",
    "So we've figured out how to get our inputs ready for machine learning but now we need to connect them to our desired output. Our model architecture is what links the two together. Let's create some hidden dense layers beginning with our inputs and end with a dense output layer. This is regression so make sure the output layer activation is correct and that the shape is right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJ7ByvoXzpVI"
   },
   "source": [
    "**Lab Task #3:** Creating DNN dense hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_outputs(inputs):\n",
    "    \"\"\"Creates model architecture and returns outputs.\n",
    "\n",
    "    Args:\n",
    "        inputs: Dense tensor used as inputs to model.\n",
    "    Returns:\n",
    "        Dense tensor output from the model.\n",
    "    \"\"\"\n",
    "    # Create two hidden layers of [64, 32] just in like the BQML DNN\n",
    "    h1 = tf.keras.layers.Dense(64, activation=\"relu\", name=\"h1\")(inputs)\n",
    "    h2 = tf.keras.layers.Dense(32, activation=\"relu\", name=\"h2\")(h1)\n",
    "\n",
    "    # Final output is a linear activation because this is regression\n",
    "    output = tf.keras.layers.Dense(\n",
    "        units=1, activation=\"linear\", name=\"weight\")(h2)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom evaluation metric.\n",
    "\n",
    "We want to make sure that we have some useful way to measure model performance for us. Since this is regression, we would like to know the RMSE of the model on our evaluation dataset, however, this does not exist as a standard evaluation metric, so we'll have to create our own by using the true and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Calculates RMSE evaluation metric.\n",
    "\n",
    "    Args:\n",
    "        y_true: tensor, true labels.\n",
    "        y_pred: tensor, predicted labels.\n",
    "    Returns:\n",
    "        Tensor with value of RMSE between true and predicted labels.\n",
    "    \"\"\"\n",
    "    return tf.sqrt(tf.reduce_mean((y_pred - y_true) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build DNN model tying all of the pieces together.\n",
    "\n",
    "Excellent! We've assembled all of the pieces, now we just need to tie them all together into a Keras Model. This is a simple feedforward model with no branching, side inputs, etc. so we could have used Keras' Sequential Model API but just for fun we're going to use Keras' Functional Model API. Here we will build the model using [tf.keras.models.Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model) giving our inputs and outputs and then compile our model with an optimizer, a loss function, and evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJ7ByvoXzpVI"
   },
   "source": [
    "**Lab Task #4:** Building DNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is our DNN architecture so far:\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "gestation_weeks (InputLayer)    [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "is_male (InputLayer)            [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mother_age (InputLayer)         [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "plurality (InputLayer)          [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_features (DenseFeatures)  (None, 11)           0           gestation_weeks[0][0]            \n",
      "                                                                 is_male[0][0]                    \n",
      "                                                                 mother_age[0][0]                 \n",
      "                                                                 plurality[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "h1 (Dense)                      (None, 64)           768         dense_features[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "h2 (Dense)                      (None, 32)           2080        h1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "weight (Dense)                  (None, 1)            33          h2[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 2,881\n",
      "Trainable params: 2,881\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 09:48:49.884499: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "def build_dnn_model():\n",
    "    \"\"\"Builds simple DNN using Keras Functional API.\n",
    "\n",
    "    Returns:\n",
    "        `tf.keras.models.Model` object.\n",
    "    \"\"\"\n",
    "    # Create input layer\n",
    "    inputs = create_input_layers()\n",
    "\n",
    "    # Create feature columns\n",
    "    feature_columns = create_feature_columns()\n",
    "\n",
    "    # The constructor for DenseFeatures takes a list of numeric columns\n",
    "    # The Functional API in Keras requires: LayerConstructor()(inputs)\n",
    "    dnn_inputs = tf.keras.layers.DenseFeatures(\n",
    "        feature_columns=feature_columns.values())(inputs)\n",
    "\n",
    "    # Get output of model given inputs\n",
    "    output = get_model_outputs(dnn_inputs)\n",
    "\n",
    "    # Build model and compile it all together\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[rmse, \"mse\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "print(\"Here is our DNN architecture so far:\\n\")\n",
    "model = build_dnn_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the DNN using the Keras plot_model utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model=model, to_file=\"dnn_model.png\", show_shapes=False, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run and evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate.\n",
    "\n",
    "We've built our Keras model using our inputs from our CSV files and the architecture we designed. Let's now run our model by training our model parameters and periodically running an evaluation to track how well we are doing on outside data as training goes on. We'll need to load both our train and eval datasets and send those to our model through the fit method. Make sure you have the right pattern, batch size, and mode when loading the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJ7ByvoXzpVI"
   },
   "source": [
    "**Lab Task #5:** Training and evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 5\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "NUM_TRAIN_EXAMPLES = 10000 * 5  # training dataset repeats, it'll wrap around\n",
    "NUM_EVALS = 5  # how many times to evaluate\n",
    "# Enough to get a reasonable sample, but not so much that it slows down\n",
    "NUM_EVAL_EXAMPLES = 10000\n",
    "\n",
    "# TODO -- Your code here.\n",
    "\n",
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // (TRAIN_BATCH_SIZE * NUM_EVALS)\n",
    "\n",
    "logdir = os.path.join(\n",
    "    \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logdir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(\n",
    "    trainds,\n",
    "    validation_data=evalds,\n",
    "    epochs=NUM_EVALS,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "nrows = 1\n",
    "ncols = 2\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "for idx, key in enumerate([\"loss\", \"rmse\"]):\n",
    "    ax = fig.add_subplot(nrows, ncols, idx+1)\n",
    "    plt.plot(history.history[key])\n",
    "    plt.plot(history.history[\"val_{}\".format(key)])\n",
    "    plt.title(\"model {}\".format(key))\n",
    "    plt.ylabel(key)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend([\"train\", \"validation\"], loc=\"upper left\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"babyweight_trained\"\n",
    "shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "EXPORT_PATH = os.path.join(\n",
    "    OUTPUT_DIR, datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
    "tf.saved_model.save(\n",
    "    obj=model, export_dir=EXPORT_PATH)  # with default serving function\n",
    "print(\"Exported trained model to {}\".format(EXPORT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $EXPORT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
